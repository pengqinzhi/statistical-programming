https://10605.github.io/

Course Overview
Large datasets pose difficulties across the machine learning pipeline. They are difficult to visualize and introduce computational, storage, 
and communication bottlenecks during data preprocessing and model training. Moreover, high capacity models often used in conjunction with large 
datasets introduce additional computational and storage hurdles during model training and inference. This course is intended to provide a student 
with the mathematical, algorithmic, and practical knowledge of issues involving learning with large datasets. Among the topics considered are: 
data cleaning, visualization, and pre-processing at scale; principles of parallel and distributed computing for machine learning; techniques for 
scalable deep learning; analysis of programs in terms of memory, computation, and (for parallel methods) communication complexity; and methods for low-latency inference.
